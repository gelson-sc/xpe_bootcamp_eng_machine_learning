import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

url = "https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
df = pd.read_csv(url)

# ğŸ”¹ 2. Selecionar a feature e a variÃ¡vel alvo
X = df[["rm"]]  # NÃºmero mÃ©dio de quartos por residÃªncia
y = df["medv"]  # PreÃ§o mÃ©dio das casas

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

# ğŸ”¹ 5. Fazer previsÃµes
y_pred = model.predict(X_test)

# ğŸ”¹ 6. Garantir que todas as previsÃµes sejam maiores que zero (para RMSLE)
y_pred = np.maximum(y_pred, 1)  # Substitui valores negativos por 1

# ğŸ”¹ 7. Calcular mÃ©tricas
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

# RMSLE - Agora nÃ£o teremos problemas com log de valores negativos
y_test_log = np.log1p(y_test)
y_pred_log = np.log1p(y_pred)
rmsle = np.sqrt(mean_squared_error(y_test_log, y_pred_log))

print(f"MSE: {mse:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"RMSLE: {rmsle:.4f}")

plt.figure(figsize=(8, 5))
sns.scatterplot(x=X_test["rm"], y=y_test, label="Dados reais", alpha=0.7)
sns.lineplot(x=X_test["rm"], y=y_pred, color="red", linewidth=2, label="RegressÃ£o Linear")
plt.xlabel("NÃºmero mÃ©dio de quartos (RM)")
plt.ylabel("PreÃ§o mÃ©dio das casas (MEDV)")
plt.legend()
plt.title("RegressÃ£o Linear: RM vs MEDV")
plt.show()
